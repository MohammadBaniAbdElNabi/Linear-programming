# 2.8.1 The Dual Problem

A linear programming problem and its dual are related in the sense that both problems are based on the same problem data, and an optimal solution to either one of the problems prescribes the optimal solution to the other. These companion problems might even be thought of as two different views of the same problem, but with different economic or engineering interpretations, and possibly with different computational implications.

Consider any linear programming formulation that is in the form of a maximization problem with constraints of the less than or equal type or equality constraints. (A constraint in which the inequality is a ≥ type can be multiplied by −1 to reverse the direction of the inequality sign, resulting possibly in a negative right-hand-side value.) We will call this the primal problem. If all constraints are inequalities and the decision variables are
non-negative, the primal problem can be written as:

$$
\begin{array}{l}
\text{maximize} \quad c_1x_1 + c_2x_2 + \dots + c_nx_n \\
\\
\text{subject to} \\
\quad a_{11}x_1 + a_{12}x_2 + \dots + a_{1n}x_n \leq b_1 \\
\quad a_{21}x_1 + a_{22}x_2 + \dots + a_{2n}x_n \leq b_2 \\
\quad \vdots \qquad \qquad \qquad \vdots \\
\quad a_{m1}x_1 + a_{m2}x_2 + \dots + a_{mn}x_n \leq b_m
\end{array}
$$


where the variables $x_1$, $\dots$ , $x_n$ are non-negative.
In general, the corresponding dual problem is constructed as follows:


• The dual problem is a minimization problem. <br>
• For every variable $x_i$ in the primal problem, there is a constraint in the dual problem. <br> 
 If $x_i ≥ 0$ in the primal, the constraint is a ≥ inequality in the dual. <br> 
 If $x_i$ is unrestricted in sign, the $i^{th}$ constraint is an equality in the dual. <br> 
• For every constraint in the primal problem, there is a variable $y_i$ in the dual. <br> 
 If the constraint is ≤, then $y_i \geq 0$ in the dual problem. <br> 
 If the constraint is an equality, then yᵢ is unrestricted in sign in the dual. <br> 
• The right hand sides in the primal are the objective function coefficients in the dual. <br> 
• The objective function coefficients in the primal are the right hand sides in the dual. <br> 
• The coefficient matrix in the primal is transposed to form the coefficient matrix for 
 the dual. <br> 

The dual problem corresponding to the earlier primal problem is a problem with $m$ variables and $n$ constraints and can be written as:

$$
\begin{array}{l}
\text{minimize} \quad b_1y_1 + b_2y_2 + \dots + b_my_m \\
\\
\text{subject to} \\
\quad a_{11}y_1 + a_{21}y_2 + \dots + a_{m1}y_m \geq c_1 \\
\quad a_{12}y_1 + a_{22}y_2 + \dots + a_{m2}y_m \geq c_2 \\
\quad \vdots \qquad \qquad \qquad \vdots \\
\quad a_{1n}y_1 + a_{2n}y_2 + \dots + a_{mn}y_m \geq c_n
\end{array}
$$

and the variables $y_1$, $\dots$ , $y_m$ are non-negative. <br> 
Clearly, the dual of the dual problem is the original primal problem, and in many contexts, it is not necessary to stipulate which one of the companion problems is the primal one
and which is the dual one; each is the dual of the other.

<ul />

**Example 2.8.1**

Consider the primal problem:

$$
\begin{align*}
\text{maximize} \quad & 3x₁ + 2x₂ - 6x₃ \\
\text{subject to} \quad & 4x₁ + 8x₂ − x₃ ≤ 5 \\
& 7x₁ - 2x₂ + 2x₃ \geq 4 \\
& x₁, x₂, x₃ ≥ 0 
\end{align*}
$$


The second constraint can be rewritten as $−7x_1 + 2x_2 − 2x_3 ≤ −4$. The dual problem is
then

$$
\begin{align*}
\text{minimize} \quad & 5y₁ − 4y₂ \\
\text{subject to} \quad & 4y₁ − 7y₂ ≥ 3 \\
& 8y₁ + 2y₂ ≥ 2 \\
& −y₁ − 2y₂ ≥ -6 \\
& y₁, y₂ ≥ 0 
\end{align*}
$$

**Example 2.8.2**

The following primal problem has constraints that include both types of inequalities
and an equality constraint:

$$
\begin{align*}
\text{maximize} \quad & 4x₁ - 3x₂ \\
\text{subject to} \quad & 2x₁ − 4x₂ ≤ 5 \\
& 5x₁ − 6x₂ \geq 9 \\
& 3x₁ + 8x₂ = 2 \\
& x₁ + 2x₂ \leq 1 \\
& \text{and }x₁ ≥ 0 \\ 
&\text{ and } x₂\text{ unrestricted in sign} 
\end{align*}
$$


The dual of this problem is formed by rewriting the second constraint as $−5x_1 + 6x_2 ≤ −9$,and then following the guidelines presented earlier to obtain:

$$
\begin{align*}
\text{minimize} \quad & 5y₁ - 9y₂ + 2y₃ + y_4 \\
\text{subject to} \quad & 2y₁ − 5y₂ + 3y₃ + y_4 ≥ 4 \\
& −4y₁ + 6y₂ + 8y₃ + 2y_4 = -3 \\
& \text{and } y₁, y₂, y_4 ≥ 0 \\
& \text{and } y₃ \text{ unrestricted in sign}
\end{align*}
$$



(Recall that the Simplex method requires that all variables be non-negative. When an unrestricted variable arises in a formulation, that variable can be replaced by the difference of two new non-negative variables, as suggested and illustrated in Section 2.4.1.) <br>
There is a very apparent structural similarity between a primal and dual pair of problems, but how are their solutions related? In the course of solving a (primal) maximization problem, the Simplex method generates a series of feasible solutions with successively larger objective function values (cx). Solving the corresponding (dual) minimization problem may be thought of as a process of generating a series of feasible solutions with successively *smaller* objective function values (yb). Assuming that an optimal solution does exist, the primal problem will converge to its maximum objective function value from below, and the dual problem will converge to its minimum objective function value from above. The primal objective function evaluated at x never exceeds the dual objective function evaluated at y; and at optimality, the two problems actually have the same objective function value. This can be summarized in the following **duality property**:

**Duality property**: If $x$ and $y$ are feasible solutions to the primal and dual problems, respectively, then $cx ≤ yb$ throughout the optimization process; and finally, at optimality, $cx^* = y^*b$.

It follows from this property that, if feasible objective function values are found for a primal and dual pair of problems, and if these values are equal to each other, then both of the solutions are optimal solutions.

The phenomenon of primal and dual problems sharing the same objective function
values is not mere coincidence. In fact, the shadow prices, which appear in the top row of the optimal tableau of the primal problem, are precisely the optimal values of the dual variables. Similarly, if the dual problem were solved using the Simplex method, the shadow prices in that optimal tableau would be the optimal values of the primal variables.

In the illustrative problem from Section 2.5, the dual objective of minimizing
$150y₁ + 250y₂ + 500y₃$ is met when the dual variables (shadow prices) have the values $y₁ = 0, y₂ = 1, y₃ = 4$. Thus, from the dual point of view,

 $$ z^* = 150(0) + 250(1) + 500(4) = 2250 $$

which is equal to the primal objective value

 $$ z^* = 8x₁ + 5x₂ = 8(125) + 5(250) = 2250 $$

for optimal $x$ values of $x₁ = 125$ and $x₂ = 250$. <br> 
One further characterization relating primal and dual linear programming problems is known as **complementary slackness**. Because each decision variable in a primal problem is associated with a constraint in the dual problem, each such variable is also associated with a slack or surplus variable in the dual. In any solution, if the primal variable is basic (with value $≥ 0$, hence having slack), then the associated dual variable is non-basic (with value $= 0$, hence having no slack). And if the primal variable is non-basic (with value $= 0$, hence no slack), then the associated dual variable is basic (with value $= 0$, hence having slack).

This can be observed even in a problem as simple as the one illustrating the Simplex method in Section 2.5. In the final tableau, the primal basic variables $x₁, s₁$, and $x₂$ have positive values, while in the top row we see zero values for their three associated dual variables. The non-basic primal variables $s₂$ and $s₃$ have zero values, while their associated dual variables are basic and have non-zero values.

This property is described as follows.

<ul/>

**Complementary Slackness Property**: If in an optimal solution to a linear programming problem, an inequality constraint is not binding, then the dual variable corresponding to that constraint has a value of zero in any optimal solution to the dual problem. 
</ul>

This is merely a formalization of the intuitive notion that the shadow price of a resource associated with a non-binding constraint is zero. That is, there is a zero marginal worth for a resource that is not being fully utilized. <br>
The properties described earlier were based on an assumption that optimal solutions to both primal and dual problems exist, but, of course, not all linear programming problems have optimal feasible solutions; infeasible problems and problems with unbounded solutions were discussed earlier in this chapter. For corresponding primal and dual problems, exactly one of the following mutually exclusive cases always occurs:

1. Both primal and dual problems are feasible, and both have optimal (and equal) solutions.
2. Both primal and dual problems are infeasible (have no feasible solution).
3. The primal problem is feasible but unbounded, and the dual problem is infeasible.
4. The dual problem is feasible but unbounded, and the primal problem is infeasible.

Because the pertinent parameters and goals of any linear programming problem can be expressed in either a primal or dual form, and because solving either the primal or dual problem yields enough information to easily construct a solution to the other, we might reasonably wonder which problem, primal or dual, should we solve when using the Simplex method.

From the standpoint of computational efficiency, we might wish to choose to solve the problem with the fewer number of constraints. As is discussed further in Section 2.10.3,the computation time required for the Simplex method is strongly dependent on the number of constraints, and almost independent of the number of variables. Therefore, in the absence of other identifiable structural characteristics of a problem that might make it amenable to the use of specialized solution methods, we could expect to be able to solve most quickly the problem having the smaller number of constraints. This choice becomes more compelling when the linear programming problem has thousands of constraints, and is of much less importance for more moderate-sized problems of a few hundred or less constraints.

An understanding of duality properties and the relation between primal and dual
problems gives an analyst some flexibility in formulating, solving, and interpreting a solution to a linear programming problem. Moreover, duality provides the mathematical basis for analyzing an optimal solution’s sensitivity to small changes in problem data. We now turn our attention to the types of analysis that can be made once an optimal solution to a linear programming problem has been obtained.

</ul>