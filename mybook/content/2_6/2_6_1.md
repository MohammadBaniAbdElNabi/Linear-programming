# 2.6 Initial Solutions for General Constraints

## 2.6.1 Artificial Variables

In the original presentation of the Simplex algorithm in **Section 2.5**, our sample problem was one in which all constraints were of the less-than-or-equal (≤) type. In that case, we observed that by adding slack variables (in order to achieve equality constraints), we fortuitously also obtained an initial feasible set of basic variables. The coefficients of the slack variables provided the required unit vectors, embedded in the matrix of coefficients of the linear system of equations. In this section, we will see how to obtain an initial basic feasible solution for problems with more general forms of constraints, and to then use the Simplex method to solve such problems.

First of all, recall that all right hand sides $b_i$ of constraints must be non-negative. Any 
constraint with a negative constant on the right hand side can be multiplied by −1 in order to satisfy this requirement. For example, an equality constraint such as: 

$$
-3x_1 + 4x_2 = -6
$$

can be replaced by the constraint

$$
3x_1 - 4x_2 = 6
$$

An inequality such as:

$$
5x_1 - 8x_2 \leq -10
$$

can be replaced by

$$
-5x_1 + 8x_2 \geq 10
$$

At this point, it should be clear that typical linear programming problems in standard form contain equality constraints involving only the original decision variables as well as constraints that include slack variables and surplus variables. Slack variables can conveniently be used as basic variables; however, basic variables corresponding to equality constraints and greater than or equal (≥) constraints are not always immediately available. Although it may be possible, by trial and error, to obtain a feasible starting basis for some problems, we prefer to use an approach that is straightforward and simple, and that can be used predictably in all cases.<br />
We will deal with this situation by introducing additional variables, called artificial variables, solely for the purpose of obtaining an initial basis. These variables have no real meaning in the problem being solved, and will not be a part of the final solution. They merely provide a mechanism that will allow us to create a starting basic solution configuration, and then to apply the Simplex algorithm to the problem. (Note that it may not be necessary to add an artificial variable to every constraint; a constraint with a slack variable does not need an artificial variable.)

As an illustration, consider the following linear programming problem:

$$
\begin{align*}
\text{maximize} \quad & z = x_1 + 3x_2 \\
\text{subject to} \quad & 2x_1 - x_2 \leq -1 \\
& x_1 + x_2 = 3 \\
& x_1, x_2 \geq 0
\end{align*}
$$

We multiply the first constraint by –1, to obtain $ -2x_1 + x_2 \geq 1 $, and then create an equality constraint by adding a (non-negative) surplus variable $ s_1 $ with a coefficient of –1. Now, the set of constraints

$$
-2x_1 + x_2 - s_1 = 1 \\
x_1 + x_2 = 3
$$

is in standard form, but since there is no obvious starting solution (as there would have been if we had added *slack* variables in each constraint), we will introduce two artificial variables, $ R_1 $ and $ R_2 $, for this purpose. The constraint set becomes

$$
-2x_1 + x_2 - s_1 + R_1 = 1 \\
x_1 + x_2 + R_2 = 3
$$

where $ x_1, x_2, s_1, R_1, R_2 \geq 0 $. We now have initial basic variables $ R_1 $ and $ R_2 $ for this enlarged problem; however, we must realize that the original equality constraint set is satisfied only if both $ R_1 $ and $ R_2 $ have values of zero. Therefore, the artificial variables must play only a temporary role in the solution.

There are two primary approaches that we can use to ensure that the artificial variables are not in the final solution. One method, commonly called the **Big-M method**, achieves this end by creating a modified objective function with huge negative coefficients $–M$ on the artificial variables. In our example, the modified objective function would be

$$
z_M = x_1 + 3x_2 + 0s_1 - M R_1 - M R_2
$$

When the Simplex method is applied to *maximize* this function, the heavy negative weights on the artificial variables will tend to drive $ R_1 $ and $ R_2 $ out of the basis, and the final solution will typically involve only the decision variables $ x_i $ and the slack or surplus variables.

For two reasons, the Big-M method is not considered to be a practical approach.

<ul />

1. If the Simplex method terminates with an optimal solution (or with an indication that the linear program is unbounded), and at least one of the artificial variables is basic (positive) in the solution, then the original problem has no feasible solution. Moreover, in order to discover that no solution exists, we have had to solve an entire large (enlarged because of the additional artificial variables) linear programming problem. 

2. A more serious difficulty with this method arises from a computational standpoint. The value of M must be chosen to be overwhelmingly large relative to all other problem parameters, in order to be sure that artificial variables do not remain in the basis of a feasible problem. However, as was pointed out in **Chapter 1**, computer arithmetic involving quantities of vastly different magnitudes leads to round-off error in which the smaller quantities (such as our original objective coefficients) are dwarfed by the artificial coefficients and are completely lost.

</ul>

Thus, despite its intuitive appeal, the Big-M method is very poorly suited for computer implementation, and nowadays is rarely seen in commercial software.

The more practical alternative to solving linear programming problems having artificial variables is found in the **two-phase** Simplex method.

